{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install requirements\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install torch torchvision opencv-python numpy"
      ],
      "metadata": {
        "id": "YptucDL6hL06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sam predictor\n",
        "import os\n",
        "\n",
        "from segment_anything import SamPredictor, sam_model_registry\n",
        "\n",
        "\n",
        "model_path = './sam_vit_b_01ec64.pth'\n",
        "if not os.path.exists(model_path):\n",
        "  !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "\n",
        "sam = sam_model_registry[\"vit_b\"](checkpoint=model_path)\n",
        "predictor = SamPredictor(sam)\n"
      ],
      "metadata": {
        "id": "ctmlophoiItz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load image and select x, y coordinates to test\n",
        "import cv2\n",
        "\n",
        "\n",
        "image_path = './test.jpg'\n",
        "if not os.path.exists(image_path):\n",
        "  !wget https://utils-computervisiondeveloper.s3.amazonaws.com/media/public/test.jpg\n",
        "\n",
        "x = 528\n",
        "y = 606\n",
        "\n",
        "image = cv2.imread(image_path)"
      ],
      "metadata": {
        "id": "GKJ3plYMiI40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use sam predictor on (image, x, y) to get location of subject\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "predictor.set_image(image)\n",
        "\n",
        "masks, scores, logits = predictor.predict(\n",
        "                                  point_coords=np.asarray([[x, y]]),\n",
        "                                  point_labels=np.asarray([1]),\n",
        "                                  multimask_output=True\n",
        "                              )\n",
        "\n",
        "C, H, W = masks.shape\n",
        "\n",
        "result_mask = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "for j in range(C):\n",
        "  result_mask |= masks[j, :, :]\n",
        "\n",
        "result_mask = result_mask.astype(np.uint8)"
      ],
      "metadata": {
        "id": "Mq2AiU_UiJDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove background\n",
        "alpha_channel = np.ones(result_mask.shape, dtype=result_mask.dtype) * 255\n",
        "\n",
        "alpha_channel[result_mask == 0] = 0\n",
        "\n",
        "result_image = cv2.merge((image, alpha_channel))"
      ],
      "metadata": {
        "id": "9fx_l59giJPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap it up as a function\n",
        "import base64\n",
        "import os\n",
        "\n",
        "from segment_anything import SamPredictor, sam_model_registry\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model_path = './sam_vit_b_01ec64.pth'\n",
        "if not os.path.exists(model_path):\n",
        "  !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "\n",
        "sam = sam_model_registry[\"vit_b\"](checkpoint=model_path)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "\n",
        "def remove_background(image_base64_encoding, x, y):\n",
        "\n",
        "  image_bytes = base64.b64decode(image_base64_encoding)\n",
        "\n",
        "  image = cv2.imdecode(np.frombuffer(image_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "  predictor.set_image(image)\n",
        "\n",
        "  masks, scores, logits = predictor.predict(\n",
        "                                    point_coords=np.asarray([[x, y]]),\n",
        "                                    point_labels=np.asarray([1]),\n",
        "                                    multimask_output=True\n",
        "                                )\n",
        "\n",
        "  C, H, W = masks.shape\n",
        "\n",
        "  result_mask = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "  for j in range(C):\n",
        "    result_mask |= masks[j, :, :]\n",
        "\n",
        "  result_mask = result_mask.astype(np.uint8)\n",
        "\n",
        "  alpha_channel = np.ones(result_mask.shape, dtype=result_mask.dtype) * 255\n",
        "\n",
        "  alpha_channel[result_mask == 0] = 0\n",
        "\n",
        "  result_image = cv2.merge((image, alpha_channel))\n",
        "\n",
        "  _, result_image_bytes = cv2.imencode('.png', result_image)\n",
        "\n",
        "  result_image_bytes = result_image_bytes.tobytes()\n",
        "\n",
        "  result_image_bytes_encoded_base64 = base64.b64encode(result_image_bytes).decode('utf-8')\n",
        "\n",
        "  return result_image_bytes_encoded_base64"
      ],
      "metadata": {
        "id": "v-t2DK56iJko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image_path = './test.jpg'\n",
        "if not os.path.exists(image_path):\n",
        "  !wget https://utils-computervisiondeveloper.s3.amazonaws.com/media/public/test.jpg\n",
        "\n",
        "x = 528\n",
        "y = 606\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "_, image_bytes = cv2.imencode('.png', image)\n",
        "\n",
        "image_bytes = image_bytes.tobytes()\n",
        "\n",
        "image_bytes_encoded_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "result_image = remove_background(image_bytes_encoded_base64, x, y)\n",
        "\n",
        "result_image_bytes = base64.b64decode(result_image)\n",
        "\n",
        "result_image = cv2.imdecode(np.frombuffer(result_image_bytes, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGRA2RGBA))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kzZJtr8FiJnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modelbit"
      ],
      "metadata": {
        "id": "a1MtkZjkoGJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import modelbit\n",
        "\n",
        "mb = modelbit.login()"
      ],
      "metadata": {
        "id": "na55DK7ponVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mb.deploy(remove_background)"
      ],
      "metadata": {
        "id": "AlOMHtW5oy6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "\n",
        "api_endpoint = None\n",
        "\n",
        "\n",
        "image_path = './test.jpg'\n",
        "if not os.path.exists(image_path):\n",
        "  !wget https://utils-computervisiondeveloper.s3.amazonaws.com/media/public/test.jpg\n",
        "\n",
        "x = 528\n",
        "y = 606\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "_, image_bytes = cv2.imencode('.png', image)\n",
        "\n",
        "image_bytes = image_bytes.tobytes()\n",
        "\n",
        "image_bytes_encoded_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "api_data = {\"data\": [image_bytes_encoded_base64, x, y]}\n",
        "response = requests.post(api_endpoint, json=api_data)\n",
        "\n",
        "result_image = response.json()['data']\n",
        "\n",
        "result_image_bytes = base64.b64decode(result_image)\n",
        "\n",
        "result_image = cv2.imdecode(np.frombuffer(result_image_bytes, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGRA2RGBA))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8-9l2hxVqXm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
